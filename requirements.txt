Happy Brain Chatbot - Jupyter Notebook/System Requirements

Here are the requirements for running mental_health_chatbot_happy_brain.ipynb on your system:

# Required libraries

datasets
evaluate
gradio
numpy
pandas
pydub
scikit-learn
speechrecognition
torch
transformers

-------------------

#Import section

# ================================
# Standard Library Imports
# ================================
import os
import glob
import json
import time
import random
import itertools
import tempfile
import datetime
import logging
import warnings
from pathlib import Path
from dataclasses import dataclass
import pprint  # for pretty-printing outputs

# ================================
# Scientific & Data Libraries
# ================================
import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from sklearn.metrics import f1_score
from sklearn.preprocessing import MultiLabelBinarizer

# ================================
# Audio Processing
# ================================
from pydub import AudioSegment
import speech_recognition as sr

# ================================
# NLP & Transformers (Hugging Face)
# ================================
from datasets import load_dataset, Dataset, concatenate_datasets
import evaluate
import gradio as gr

# Tokenizers and Models
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    T5ForConditionalGeneration,
)

# Training Tools
from transformers import (
    Trainer,
    TrainingArguments,
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments,
    TrainerCallback,
    DataCollatorWithPadding,
    DataCollatorForSeq2Seq,
    default_data_collator,
)

# Logging
from transformers import logging as hf_logging

-------------------

If you have a GPU, use this (regardless, it'll fall back to cpu):

device = torch.device("cuda:0")
print("GPU Available:", torch.cuda.is_available())  # True if a GPU is accessible
print("Current Device Index:", torch.cuda.current_device())  # e.g., 0
print("Device Name:", torch.cuda.get_device_name(0))  # e.g., "NVIDIA GeForce RTX 3070"

# Example: set default tensor type to GPU-based FloatTensor (optional)
# This will make ALL newly created tensors go to GPU (Float32).
# torch.set_default_tensor_type(torch.cuda.FloatTensor) <- Note: Uncommenting can cause downstream training functions to generate this error. (RuntimeError: Expected a 'cuda' device type for generator but found 'cpu')

Install PyTorch with CUDA Support:

pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu111

or,

conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia (I think this one works the best.)
