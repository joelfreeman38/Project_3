{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feef30d5",
   "metadata": {},
   "source": [
    "# Mental Health Chatbot Trainer – Full Pipeline\n",
    "\n",
    "This notebook trains a multi-model chatbot with emotional intelligence and conversational memory.\n",
    "\n",
    "**Models Trained:**\n",
    "- Emotion Classifier: `SamLowe/roberta-base-go_emotions`\n",
    "- Response Generator: `T5`\n",
    "- Q&A Assistant: `T5`\n",
    "\n",
    "**Datasets Used:**\n",
    "- `mental_health_faq_cleaned.csv`\n",
    "- `transformed_mental_health_chatbot.csv`\n",
    "- `Mental Health Chatbot Dataset - Friend mode and Professional mode Responses.csv`\n",
    "- `transformed_mental_health_chatbot_dataset.csv`\n",
    "- HuggingFace datasets:\n",
    "  - `tolu07/Mental_Health_FAQ`\n",
    "  - `Amod/mental_health_counseling_conversations`\n",
    "  - `ruslanmv/ai-medical-chatbot`\n",
    "  - `lavita/ChatDoctor-HealthCareMagic-100k`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0d342",
   "metadata": {},
   "source": [
    "## 1. Load, Clean, and Merge All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0457f4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mward\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mward\\AppData\\Roaming\\Python\\Python310\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "import gradio as gr\n",
    "from evaluate import load as load_metric\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from accelerate import init_empty_weights\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2914402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "Current Device Index: 0\n",
      "Device Name: NVIDIA GeForce RTX 3070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "print(\"GPU Available:\", torch.cuda.is_available())  # True if a GPU is accessible\n",
    "print(\"Current Device Index:\", torch.cuda.current_device())  # e.g., 0\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0))  # e.g., \"NVIDIA GeForce RTX 3070\"\n",
    "\n",
    "# Example: set default tensor type to GPU-based FloatTensor (optional)\n",
    "# This will make ALL newly created tensors go to GPU (Float32).\n",
    "# torch.set_default_dtype(torch.float32)\n",
    "# torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5248c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local CSVs\n",
    "df1 = pd.read_csv('./data/mental_health_faq_cleaned.csv')\n",
    "df2 = pd.read_csv('./data/transformed_mental_health_chatbot.csv')\n",
    "df3 = pd.read_csv('./data/Mental Health Chatbot Dataset - Friend mode and Professional mode Responses.csv')\n",
    "df4 = pd.read_csv('./data/transformed_mental_health_chatbot_dataset.csv')\n",
    "\n",
    "# Harmonize column names for local files\n",
    "local_dfs = [df1, df2, df3, df4]\n",
    "for i in range(len(local_dfs)):\n",
    "    df = local_dfs[i]\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    if \"questions\" in df.columns and \"answers\" in df.columns:\n",
    "        df = df.rename(columns={\"questions\": \"question\", \"answers\": \"answer\"})\n",
    "    elif \"question\" not in df.columns or \"answer\" not in df.columns:\n",
    "        raise ValueError(f\"Dataset {i+1} is missing required 'question'/'answer' columns: {df.columns.tolist()}\")\n",
    "    local_dfs[i] = df[[\"question\", \"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e35c68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HuggingFace datasets\n",
    "ds1 = load_dataset(\"tolu07/Mental_Health_FAQ\")\n",
    "ds2 = load_dataset(\"Amod/mental_health_counseling_conversations\")\n",
    "ds3 = load_dataset(\"ruslanmv/ai-medical-chatbot\")\n",
    "ds4 = load_dataset(\"lavita/ChatDoctor-HealthCareMagic-100k\")\n",
    "\n",
    "# Harmonize HF datasets\n",
    "def extract_qa(dataset, question_key, answer_key, drop_cols=None):\n",
    "    data = dataset['train']\n",
    "    df = pd.DataFrame({ 'question': data[question_key], 'answer': data[answer_key] })\n",
    "    if drop_cols:\n",
    "        df.drop(columns=drop_cols, errors='ignore', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de7308d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "answer",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "aaf8d552-83b7-4e2d-a935-2651b71533ec",
       "rows": [
        [
         "0",
         "What does it mean to have a mental illness?",
         "Mental illnesses are health conditions that disrupt a personâ€™s thoughts, emotions, relationships, and daily functioning. They are associated with distress and diminished capacity to engage in the ordinary activities of daily life.\nMental illnesses fall along a continuum of severity: some are fairly mild and only interfere with some aspects of life, such as certain phobias. On the other end of the spectrum lie serious mental illnesses, which result in major functional impairment and interference with daily life. These include such disorders as major depression, schizophrenia, and bipolar disorder, and may require that the person receives care in a hospital.\nIt is important to know that mental illnesses are medical conditions that have nothing to do with a personâ€™s character, intelligence, or willpower. Just as diabetes is a disorder of the pancreas, mental illness is a medical condition due to the brainâ€™s biology.\nSimilarly to how one would treat diabetes with medication and insulin, mental illness is treatable with a combination of medication and social support. These treatments are highly effective, with 70-90 percent of individuals receiving treatment experiencing a reduction in symptoms and an improved quality of life. With the proper treatment, it is very possible for a person with mental illness to be independent and successful."
        ],
        [
         "1",
         "Who does mental illness affect?",
         "It is estimated that mental illness affects 1 in 5 adults in America, and that 1 in 24 adults have a serious mental illness. Mental illness does not discriminate; it can affect anyone, regardless of gender, age, income, social status, ethnicity, religion, sexual orientation, or background.\nAlthough mental illness can affect anyone, certain conditions may be more common in different populations. For instance, eating disorders tend to occur more often in females, while disorders such as attention deficit/hyperactivity disorder is more prevalent in children.\nAdditionally, all ages are susceptible, but the young and the old are especially vulnerable. Mental illnesses usually strike individuals in the prime of their lives, with 75 percent of mental health conditions developing by the age of 24. This makes identification and treatment of mental disorders particularly difficult, because the normal personality and behavioral changes of adolescence may mask symptoms of a mental health condition.\nParents and caretakers should be aware of this fact, and take notice of changes in their childâ€™s mood, personality, personal habits, and social withdrawal. When these occur in children under 18, they are referred to as serious emotional disturbances (SEDs)."
        ],
        [
         "2",
         "What causes mental illness?",
         "It is estimated that mental illness affects 1 in 5 adults in America, and that 1 in 24 adults have a serious mental illness. Mental illness does not discriminate; it can affect anyone, regardless of gender, age, income, social status, ethnicity, religion, sexual orientation, or background. Although mental illness can affect anyone, certain conditions may be more common in different populations. For instance, eating disorders tend to occur more often in females, while disorders such as attention deficit/hyperactivity disorder is more prevalent in children. Additionally, all ages are susceptible, but the young and the old are especially vulnerable. Mental illnesses usually strike individuals in the prime of their lives, with 75 percent of mental health conditions developing by the age of 24. This makes identification and treatment of mental disorders particularly difficult, because the normal personality and behavioral changes of adolescence may mask symptoms of a mental health condition. Parents and caretakers should be aware of this fact, and take notice of changes in their child’s mood, personality, personal habits, and social withdrawal. When these occur in children under 18, they are referred to as serious emotional disturbances (SEDs)."
        ],
        [
         "3",
         "What are some of the warning signs of mental illness?",
         "Symptoms of mental health disorders vary depending on the type and severity of the condition. The following is a list of general symptoms that may suggest a mental health disorder, particularly when multiple symptoms are expressed at once.\nIn adults:\nConfused thinking\nLong-lasting sadness or irritability\nExtreme highs and lows in mood\nExcessive fear, worrying, or anxiety\nSocial withdrawal\nDramatic changes in eating or sleeping habits\nStrong feelings of anger\nDelusions or hallucinations (seeing or hearing things that are not really there)\nIncreasing inability to cope with daily problems and activities\nThoughts of suicide\nDenial of obvious problems\nMany unexplained physical problems\nAbuse of drugs and/or alcohol\n  In older children and pre-teens:\nAbuse of drugs and/or alcohol\nInability to cope with daily problems and activities\nChanges in sleeping and/or eating habits\nExcessive complaints of physical problems\nDefying authority, skipping school, stealing, or damaging property\nIntense fear of gaining weight\nLong-lasting negative mood, often along with poor appetite and thoughts of death\nFrequent outbursts of anger\n  In younger children:\nChanges in school performance\nPoor grades despite strong efforts\nExcessive worrying or anxiety\nHyperactivity\nPersistent nightmares\nPersistent disobedience and/or aggressive behavior\nFrequent temper tantrums"
        ],
        [
         "4",
         "Can people with mental illness recover?",
         "When healing from mental illness, early identification and treatment are of vital importance. Based on the nature of the illness, there are a range of effective treatments available. For any type of treatment, it is essential that the person affected is proactive and fully engaged in their own recovery process.\nMany people with mental illnesses who are diagnosed and treated respond well, although some might experience a return of symptoms. Even in such cases, with careful monitoring and management of the disorder, it is still quite possible to live a fulfilled and productive life."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does it mean to have a mental illness?</td>\n",
       "      <td>Mental illnesses are health conditions that di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who does mental illness affect?</td>\n",
       "      <td>It is estimated that mental illness affects 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What causes mental illness?</td>\n",
       "      <td>It is estimated that mental illness affects 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some of the warning signs of mental i...</td>\n",
       "      <td>Symptoms of mental health disorders vary depen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can people with mental illness recover?</td>\n",
       "      <td>When healing from mental illness, early identi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0        What does it mean to have a mental illness?   \n",
       "1                    Who does mental illness affect?   \n",
       "2                        What causes mental illness?   \n",
       "3  What are some of the warning signs of mental i...   \n",
       "4            Can people with mental illness recover?   \n",
       "\n",
       "                                              answer  \n",
       "0  Mental illnesses are health conditions that di...  \n",
       "1  It is estimated that mental illness affects 1 ...  \n",
       "2  It is estimated that mental illness affects 1 ...  \n",
       "3  Symptoms of mental health disorders vary depen...  \n",
       "4  When healing from mental illness, early identi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dfs = [\n",
    "    extract_qa(ds1, question_key=\"Questions\", answer_key=\"Answers\", drop_cols=[\"Question_ID\"]),\n",
    "    extract_qa(ds2, question_key=\"Context\", answer_key=\"Response\"),\n",
    "    extract_qa(ds3, question_key=\"Patient\", answer_key=\"Doctor\"),\n",
    "    extract_qa(ds4, question_key=\"input\", answer_key=\"output\")  # Map 'input' to 'question' and 'output' to 'answer'\n",
    "]\n",
    "\n",
    "# Combine all datasets\n",
    "all_dfs = local_dfs + hf_dfs\n",
    "full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "full_df.dropna(subset=[\"question\", \"answer\"], inplace=True)\n",
    "full_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save unified dataset\n",
    "full_df.to_csv(\"./data/unified_mental_health_chatbot_dataset.csv\", index=False)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4cf0a3",
   "metadata": {},
   "source": [
    "## 2. Train Emotion Classifier (`SamLowe/roberta-base-go_emotions`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cdf2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"SamLowe/roberta-base-go_emotions\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d6be77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=28, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "fine_tuned_model.to(device)\n",
    "fine_tuned_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b67a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and run inference for emotion prediction\n",
    "full_df = pd.read_csv(\"./data/unified_mental_health_chatbot_dataset.csv\")\n",
    "questions = full_df['question'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f73ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 915/22613 [03:51<3:27:46,  1.74it/s]"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "batch_size = 16\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(questions), batch_size)):\n",
    "        batch = questions[i:i+batch_size]\n",
    "        batch = [str(q) for q in batch if isinstance(q, str) or pd.notna(q)]  # clean/sanitize\n",
    "        try:\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            outputs = fine_tuned_model(**inputs)\n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "            preds = (probs > 0.5).int().tolist()\n",
    "            predicted_labels.extend([','.join(map(str, [i for i, val in enumerate(p) if val == 1])) for p in preds])\n",
    "        except Exception as e:\n",
    "            print(f\"Error at batch {i}: {e}\")\n",
    "            predicted_labels.extend([\"\"] * len(batch))  # pad with empty if failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cb165",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save emotion-labeled data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpredicted_labels\u001b[49m\n\u001b[0;32m      3\u001b[0m full_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/emotion_labeled_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved labeled dataset to emotion_labeled_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Save emotion-labeled data\n",
    "full_df['label'] = predicted_labels\n",
    "full_df.to_csv(\"./data/emotion_labeled_dataset.csv\", index=False)\n",
    "print(\"Saved labeled dataset to emotion_labeled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare multi-hot encoded dataset for fine-tuning\n",
    "raw_df = pd.read_csv(\"./data/emotion_labeled_dataset.csv\")\n",
    "raw_df['label'] = raw_df['label'].apply(lambda x: list(map(int, str(x).split(','))) if pd.notna(x) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7fca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "multi_hot = mlb.fit_transform(raw_df['label'])\n",
    "label_cols = [f\"label_{i}\" for i in range(multi_hot.shape[1])]\n",
    "raw_df[label_cols] = multi_hot\n",
    "raw_df = raw_df.drop(columns=[\"label\"])\n",
    "raw_df = raw_df.rename(columns={\"question\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c279d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 289443/289443 [01:48<00:00, 2658.51 examples/s]\n",
      "Map: 100%|██████████| 72361/72361 [00:27<00:00, 2648.55 examples/s]\n",
      "Map: 100%|██████████| 289443/289443 [01:48<00:00, 2661.18 examples/s]\n",
      "Map: 100%|██████████| 72361/72361 [00:27<00:00, 2647.64 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and prepare Hugging Face dataset\n",
    "dataset = Dataset.from_pandas(raw_df)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "def tokenize(batch):\n",
    "    texts = [str(t) if pd.notna(t) else \"\" for t in batch[\"text\"]]\n",
    "    return tokenizer(texts, padding=True, truncation=True)\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "\n",
    "def merge_labels(example):\n",
    "    example['labels'] = torch.tensor([example[f'label_{i}'] for i in range(len(label_cols))])\n",
    "    return example\n",
    "\n",
    "tokenized = tokenized.map(merge_labels)\n",
    "tokenized.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63667d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Trainer for multi-label classification\n",
    "class MultiLabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits, labels.type_as(logits))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b9958",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set up TrainingArguments\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./saved_models/roberta_emotion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set up TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./saved_models/roberta_emotion\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532219d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train using custom MultiLabelTrainer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MultiLabelTrainer(\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mfine_tuned_model,\n\u001b[1;32m----> 4\u001b[0m     args\u001b[38;5;241m=\u001b[39m\u001b[43mtraining_args\u001b[49m,\n\u001b[0;32m      5\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_args' is not defined"
     ]
    }
   ],
   "source": [
    "# Train using custom MultiLabelTrainer\n",
    "trainer = MultiLabelTrainer(\n",
    "    model=fine_tuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Save fine-tuned model and tokenizer\n",
    "fine_tuned_model.save_pretrained(\"./saved_models/roberta_emotion\")\n",
    "tokenizer.save_pretrained(\"./saved_models/roberta_emotion\")\n",
    "print(\"Fine-tuned multi-label model saved to ./saved_models/roberta_emotion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4152513",
   "metadata": {},
   "source": [
    "## 3. Train T5 for Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model_name = \"t5-small\"\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(t5_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [\"question: \" + q for q in examples[\"question\"]]\n",
    "    model_inputs = tokenizer_t5(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    with tokenizer_t5.as_target_tokenizer():\n",
    "        labels = tokenizer_t5(examples[\"answer\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bdf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_dataset = Dataset.from_pandas(full_df[['question', 'answer']])\n",
    "t5_dataset = t5_dataset.train_test_split(test_size=0.2)\n",
    "tokenized_t5 = t5_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_t5 = TrainingArguments(\n",
    "    output_dir=\"./saved_models/t5_response_generator\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddaecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_t5 = Trainer(\n",
    "    model=model_t5,\n",
    "    args=args_t5,\n",
    "    train_dataset=tokenized_t5[\"train\"],\n",
    "    eval_dataset=tokenized_t5[\"test\"],\n",
    "    tokenizer=tokenizer_t5,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer_t5, model=model_t5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfe3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer_t5.train()\n",
    "model_t5.save_pretrained(\"./saved_models/t5_response_generator\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf3292",
   "metadata": {},
   "source": [
    "## 4. Train T5 for Q&A Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e0572",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_df = full_df[full_df['answer'].str.contains(\"Bro|Yo|Hey|Dude|Ugh|memes|suck|spill\", case=False) == False]\n",
    "\n",
    "qa_dataset = Dataset.from_pandas(prof_df[['question', 'answer']])\n",
    "qa_dataset = qa_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "def preprocess_qa(examples):\n",
    "    inputs = [\"question: \" + q for q in examples[\"question\"]]\n",
    "    model_inputs = tokenizer_t5(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    with tokenizer_t5.as_target_tokenizer():\n",
    "        labels = tokenizer_t5(examples[\"answer\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_qa = qa_dataset.map(preprocess_qa, batched=True)\n",
    "model_t5_qa = T5ForConditionalGeneration.from_pretrained(t5_model_name)\n",
    "\n",
    "args_qa = TrainingArguments(\n",
    "    output_dir=\"./saved_models/t5_qa_assistant\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_qa = Trainer(\n",
    "    model=model_t5_qa,\n",
    "    args=args_qa,\n",
    "    train_dataset=tokenized_qa[\"train\"],\n",
    "    eval_dataset=tokenized_qa[\"test\"],\n",
    "    tokenizer=tokenizer_t5,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer_t5, model=model_t5_qa)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf67342",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_qa.train()\n",
    "model_t5_qa.save_pretrained(\"./saved_models/t5_qa_assistant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6109136f",
   "metadata": {},
   "source": [
    "## 5. Emotion-Aware T5 Response Generator & QA Assistant Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emotion-enriched dataset\n",
    "df = pd.read_csv(\"./data/t5_emotion_augmented_dataset.csv\")\n",
    "dataset = Dataset.from_pandas(df[[\"emotion_name\", \"question\", \"answer\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format input: emotion: [emotion] question: [question]\n",
    "def preprocess(example):\n",
    "    inputs = [f\"emotion: {e} question: {q}\" for e, q in zip(example[\"emotion_name\"], example[\"question\"])]\n",
    "    targets = example[\"answer\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=512, padding=\"max_length\", truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d54400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset\n",
    "tokenized = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TRAINING: Response Generator\n",
    "# ------------------------\n",
    "model_response = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "args_response = TrainingArguments(\n",
    "    output_dir=\"./saved_models/t5_response_emotion_aware\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c83c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_response = Trainer(\n",
    "    model=model_response,\n",
    "    args=args_response,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model_response)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3751af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_response.train()\n",
    "model_response.save_pretrained(\"./saved_models/t5_response_emotion_aware\")\n",
    "print(\"✅ Trained and saved: t5_response_emotion_aware\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604878e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# TRAINING: QA Assistant\n",
    "# ------------------------\n",
    "model_qa = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "args_qa = TrainingArguments(\n",
    "    output_dir=\"./saved_models/t5_qa_emotion_aware\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00aa167",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_qa = Trainer(\n",
    "    model=model_qa,\n",
    "    args=args_qa,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model_qa)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ba5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer_qa.train()\n",
    "model_qa.save_pretrained(\"./saved_models/t5_qa_emotion_aware\")\n",
    "print(\"✅ Trained and saved: t5_qa_emotion_aware\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edae096",
   "metadata": {},
   "source": [
    "## 6. Gradio Chatbot Interface (Emotion-Aware with Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load all models\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "model_roberta = AutoModelForSequenceClassification.from_pretrained(\"./saved_models/roberta_emotion\")\n",
    "id2label = model_roberta.config.id2label\n",
    "\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(\"./saved_models/t5_response_emotion_aware\")\n",
    "model_qa = T5ForConditionalGeneration.from_pretrained(\"./saved_models/t5_qa_emotion_aware\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    global chat_history\n",
    "\n",
    "    # Detect Emotion\n",
    "    emo_inputs = tokenizer_roberta(user_input, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        emo_outputs = model_roberta(**emo_inputs)\n",
    "    emotion = id2label[int(torch.argmax(emo_outputs.logits, dim=1))]\n",
    "\n",
    "    # Support message\n",
    "    support_msg = \"I'm here for you.\" if emotion != \"neutral\" else \"Let’s talk more about how you're feeling.\"\n",
    "\n",
    "    # Emotion-aware prompt\n",
    "    prompt = f\"emotion: {emotion} question: {user_input}\"\n",
    "    input_ids = tokenizer_t5(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # Generate Responses\n",
    "    with torch.no_grad():\n",
    "        response_ids = model_t5.generate(input_ids, max_length=100)\n",
    "        response_text = tokenizer_t5.decode(response_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        qa_ids = model_qa.generate(input_ids, max_length=100)\n",
    "        qa_text = tokenizer_t5.decode(qa_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Chat memory\n",
    "    combined_response = (\n",
    "        f\"Detected Emotion: {emotion}\\n\"\n",
    "        f\"Empathy: {support_msg}\\n\"\n",
    "        f\"Response: {response_text}\\n\"\n",
    "        f\"Answer: {qa_text}\"\n",
    "    )\n",
    "    chat_history.append((f\"You: {user_input}\", f\"{combined_response}\"))\n",
    "    return \"\\n\\n\".join([f\"{q}\\n{a}\" for q, a in chat_history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745647d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chatbot_response, title=\"🧠 Emotion-Aware Mental Health Chatbot\", description=\"Ask any question or share how you're feeling. The bot will respond with empathy and advice.\").launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a8f41",
   "metadata": {},
   "source": [
    "## 7. Evaluate Models (ROUGE, BERTScore, Perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample evaluation on response generation\n",
    "sample_batch = tokenized_t5[\"test\"].select(range(50))\n",
    "predictions = trainer_t5.predict(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc32460",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_preds = tokenizer_t5.batch_decode(predictions.predictions, skip_special_tokens=True)\n",
    "decoded_labels = tokenizer_t5.batch_decode(sample_batch[\"labels\"], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE Evaluation\n",
    "rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "# BERTScore Evaluation\n",
    "bertscore_result = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity Calculation\n",
    "losses = []\n",
    "for i in range(len(sample_batch)):\n",
    "    input_ids = torch.tensor([sample_batch[i][\"input_ids\"]]).to(model_t5.device)\n",
    "    labels = torch.tensor([sample_batch[i][\"labels\"]]).to(model_t5.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_t5(input_ids=input_ids, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate perplexity\n",
    "import math\n",
    "perplexity = math.exp(sum(losses)/len(losses))\n",
    "\n",
    "rouge_result, bertscore_result, perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
