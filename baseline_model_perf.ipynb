{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mward\\AppData\\Roaming\\Python\\Python310\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mward\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mward\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mward\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HF_HOME: c:\\Users\\mward\\Project_3\\hf_cache\n",
      "Loading tokenizer and model using cache_dir = c:\\Users\\mward\\Project_3\\hf_cache...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674df0cc6d824cbf9f48f199458c1815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95cb788f317435c9d4015888649b64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:  24%|##4       | 870M/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe13e4ba3db465e9ccaa617b64dbc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:  24%|##3       | 1.16G/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99819ece759e4fe28e4ea802a0d06be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:  26%|##6       | 1.30G/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/8f/99/8f991a3329a6eab513a218c979c1e3d9409e6be2b69f315fd96a0312fe23efa8/b2bf4c94feb4e375cfbcd4c4cdcf74ac5e318f47318d7f63907d2e53aee0302d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00003.safetensors%3B+filename%3D%22model-00002-of-00003.safetensors%22%3B&Expires=1743741468&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0Mzc0MTQ2OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzhmLzk5LzhmOTkxYTMzMjlhNmVhYjUxM2EyMThjOTc5YzFlM2Q5NDA5ZTZiZTJiNjlmMzE1ZmQ5NmEwMzEyZmUyM2VmYTgvYjJiZjRjOTRmZWI0ZTM3NWNmYmNkNGM0Y2RjZjc0YWM1ZTMxOGY0NzMxOGQ3ZjYzOTA3ZDJlNTNhZWUwMzAyZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=RX5WA58SfBxHwNNBs0hCIdqSupHJFfzGkR-OtHwlJWWkG2ktsa2-58MoxevjRvjqNHGgygEWA2-iE0r5ZmdSRA9pVlj0lEuRlYVxDwBljM238mA9hjfzHRpKjYGki7zjjwUAw1x%7Eu1rdmmXebb9ugZmmClfOhz5YEYeMnecPrFNi5SGX7mKfd7uhSHX0IR-fee2ES3ExBa9ifg%7ExtPuvxiS5A90mfJk9mVNSicApdrmFxKrtHPg29QJtYKIhPsBk8tCJDDQuB-mzzzY2ltINmNqXj7hwQhQVP2%7EaTPWpX3QKI5W86IMSNlLGEKQU5jE%7E9hyYT8HP6FMV0htrMFwUYg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61aedf04675f4318ac2ad13ba7558f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:  31%|###       | 1.52G/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os   \n",
    "import stat  \n",
    "import math  \n",
    "import torch  \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM  \n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu  \n",
    "from nltk.translate.meteor_score import meteor_score  \n",
    "from rouge_score import rouge_scorer  \n",
    "from sentence_transformers import SentenceTransformer  \n",
    "from sklearn.metrics.pairwise import cosine_similarity   \n",
    "\n",
    "# Set device\n",
    "# Force selection of the NVIDIA GPU (assumed as device 0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Download necessary NLTK resources  \n",
    "nltk.download('punkt')  \n",
    "nltk.download('wordnet')  \n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Set HF_HOME to a local, writable directory.  \n",
    "os.environ[\"HF_HOME\"] = os.path.join(os.getcwd(), \"hf_cache\")  \n",
    "cache_dir = os.environ[\"HF_HOME\"]  \n",
    "  \n",
    "if not os.path.exists(cache_dir):  \n",
    "    os.makedirs(cache_dir, exist_ok=True)  \n",
    "  \n",
    "print(\"Using HF_HOME:\", cache_dir)  \n",
    "  \n",
    "# Initialize the tokenizer and model using the local cache directory.  \n",
    "print(\"Loading tokenizer and model using cache_dir = \" + cache_dir + \"...\")  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kashyaparun/Mental-Health-Chatbot-using-RoBERTa-fine-tuned-on-GoEmotion\", cache_dir=cache_dir)  \n",
    "model = AutoModelForCausalLM.from_pretrained(\"kashyaparun/Mental-Health-Chatbot-using-RoBERTa-fine-tuned-on-GoEmotion\", cache_dir=cache_dir)  \n",
    "model.eval()  # Set the model to evaluation mode  \n",
    "  \n",
    "# Download necessary NLTK resources.  \n",
    "nltk.download('punkt')  \n",
    "  \n",
    "print(\"Tokenizer and model loaded successfully.\")  \n",
    "print(\"Vocabulary size:\", model.config.vocab_size)  \n",
    "print(\"Model max length:\", tokenizer.model_max_length)  \n",
    "  \n",
    "# Updated compute_perplexity function that replaces out-of-range token IDs with the unknown token.  \n",
    "def compute_perplexity(text):  \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=tokenizer.model_max_length).to(model.device)  \n",
    "    input_ids = inputs[\"input_ids\"]  \n",
    "    vocab_size = model.config.vocab_size  \n",
    "    unk_token_id = tokenizer.unk_token_id if tokenizer.unk_token_id is not None else 0  \n",
    "    input_ids_fixed = torch.where(input_ids >= vocab_size, torch.tensor(unk_token_id, device=input_ids.device), input_ids)  \n",
    "    inputs[\"input_ids\"] = input_ids_fixed  \n",
    "    with torch.no_grad():  \n",
    "        outputs = model(**inputs, labels=input_ids_fixed)  \n",
    "    loss = outputs.loss.item()  \n",
    "    perplexity = math.exp(loss)  \n",
    "    return perplexity  \n",
    "  \n",
    "# Test the function with sample evaluation texts.  \n",
    "eval_texts = [  \n",
    "    \"I feel anxious and don't know what to do.\",  \n",
    "    \"I'm depressed and need someone to talk to.\",  \n",
    "    \"I feel overwhelmed with stress at work.\"  \n",
    "]  \n",
    "  \n",
    "print(\"Evaluating Perplexity after fix:\")  \n",
    "for text in eval_texts:  \n",
    "    ppl = compute_perplexity(text)  \n",
    "    print(\"Text: \" + text)  \n",
    "    print(\"Perplexity: \" + str(ppl))  \n",
    "    print(\"-----\")  \n",
    "  \n",
    "print(\"done\")  \n",
    "\n",
    "# Load a sentence transformer model for semantic similarity  \n",
    "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "  \n",
    "def evaluate_response_quality(generated_response, reference_response):  \n",
    "    # Tokenize responses  \n",
    "    gen_tokens = nltk.word_tokenize(generated_response.lower())  \n",
    "    ref_tokens = nltk.word_tokenize(reference_response.lower())  \n",
    "      \n",
    "    # Calculate BLEU score (using a simple 4-gram setting)  \n",
    "    bleu = sentence_bleu([ref_tokens], gen_tokens)  \n",
    "      \n",
    "    # Calculate METEOR score  \n",
    "    meteor = meteor_score([ref_tokens], gen_tokens)  \n",
    "      \n",
    "    # Calculate ROUGE scores  \n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)  \n",
    "    rouge_scores = scorer.score(reference_response, generated_response)  \n",
    "      \n",
    "    # Calculate semantic similarity using embeddings  \n",
    "    embeddings = semantic_model.encode([reference_response, generated_response])  \n",
    "    semantic_sim = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]  \n",
    "      \n",
    "    return {  \n",
    "        'bleu': bleu,  \n",
    "        'meteor': meteor,  \n",
    "        'rouge1_f': rouge_scores['rouge1'].fmeasure,  \n",
    "        'rouge2_f': rouge_scores['rouge2'].fmeasure,  \n",
    "        'rougeL_f': rouge_scores['rougeL'].fmeasure,  \n",
    "        'semantic_similarity': semantic_sim  \n",
    "    }  \n",
    "  \n",
    "# Example usage:  \n",
    "reference = \"I'm sorry you're feeling anxious. It might help to try some deep breathing exercises and reach out to someone you trust.\"  \n",
    "generated = \"I understand that you're anxious. Perhaps deep breathing and talking with a friend might ease some stress.\"  \n",
    "  \n",
    "metrics = evaluate_response_quality(generated, reference)  \n",
    "print(\"Evaluation Metrics:\")  \n",
    "for metric, value in metrics.items():  \n",
    "    print(metric + \": \" + str(value))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
